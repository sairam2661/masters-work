We broadly discussed two ideas,

1. Directed greybox fuzzing
2. Adaptive grammar/generator based fuzzing

| Property         | Directed greybox fuzzing (DGF)         | Adaptive grammar/generator fuzzing (AGF) |
| ---------------- | -------------------------------------- | ---------------------------------------- |
| Goal             | Reach specific target(s)               | General exploration (coverage or bugs)   |
| Input generation | Mutation-based on seed corpus          | Generate valid seeds via grammar         |
| Measure          | Distance-to-target                     | Form of feedback (coverage metrics)      |
| Analysis Method  | Static analysis on control-flow graphs | Dynamic analysis on coverage metrics     |
| Structure        | Less structured, raw mutations         | Structured, grammar-level mutations      |
| Examples         | AFLGo, BEACON, SieveFuzz               | Pythia, BeDivFuzz, APIRL, CovRL          |

Takeaways,

- Adaptive grammar/generator fuzzing (AGF) looks interesting

  - We already generate valid seeds using GCD/MCMC
  - Need to add an adaptive feedback loop?
  - What target do we select? Previous works,
    - Pythia – REST API sequences
    - BeDivFuzz – Java server software (Ant, Maven, Tomcat)
    - APIRL – Deep Q-learning for REST APIs
    - CovRL – LLM + RL for JS engines

- Feedback approaches,

| Metric             | Nature    | Requirements                                        |
| ------------------ | --------- | --------------------------------------------------- |
| Coverage / Error   | Black-box | Instrument program at runtime; observe new branches |
| Distance-to-target | Grey-box  | Compute static distances                            |

> Note: existing/above AGF tools use only coverage/error. Integrating distance-based metrics?

- Simple feedback loop,

1. Seed pool

   - pre-computed seeds using GCD

$$
\text{Seeds} = \{s_0,…,s_N\}
$$

2. Mode weights

   - for _choosing_ a proposal mode

$$
w_m \;→\;1.0\quad(m\in\{\text{uniform},\text{priority},\text{restart}\})
$$

3. One chain (k steps)

   ```text
   s ← pop(seeds)
   for i=1…k:
     choose m with P(m)=wₘ/∑w
     s' ← proposal-step(s, mode=m)
     α ← min(1, [π(s')q(s|s')]/[π(s)q(s'|s)])
     s ← (rand()<α)? s' : s
   ```

4. Reward and update

   $$
   r = \Delta\text{coverage}(s),\quad w_m \;+\!=\;\eta\,r
   $$

5. Requeue

   $$
   \text{push}(s,\;\text{Seeds})
   $$

Repeat until timeout/exhausted queue; $\{w_m\}$ learns which proposal styles yield the best coverage.

- Questions,
  - How do we ensure high throughput of seeds/test cases?
  - How do we ensure diversity of samples for a domain?
