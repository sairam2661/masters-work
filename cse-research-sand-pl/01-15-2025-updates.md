This week:

- read about self-learning vs retrieval-augmented-generation (RAGs) for LLMs to synthesise programs (formal guarantees?)
- refine prompts to produce function bodies cleanly, minimal extraneous text (existing prompt template has redundant steps to ensure this)
- lit survey on synthetic data generation for programs
  - enrich existing standard benchmarks
  - extract speficiations from popular programming repos
  - mutations (balance semantic properties)
  - templates (domain-agnostic?)

Next week:

- read about mutation strategies for generating synthetic data
- continue current work

Short term:

- quality of synthetic data
- diversity of benchmarks
- minimal reproducible code for generating synthetic data
- better few-shot prompting (which benchmarks to use?)
- contribute to existing SemGuS solvers (ks2)

Long term:

- taxonomy of SemGuS problems to measure coverage
- generating good SemGuS benchmarks (meaningful, diverse) for LLMs
- contribute to existing SemGuS solvers (ks2)
